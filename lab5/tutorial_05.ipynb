{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import Lars\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pprint\n",
    "import csv\n",
    "import codecs\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "import glob\n",
    "import codecs\n",
    "import re\n",
    "import pandas as pd\n",
    "import math\n",
    "from cmath import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "from matplotlib.pyplot import *\n",
    "from numpy.linalg import inv\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# sns.reset_orig()\n",
    "np.random.seed(0)\n",
    "sns.set_theme(context='notebook')\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import isnan, isinf, float64\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.estimator_checks import *\n",
    "import warnings\n",
    "from sklearn.utils.validation import DataConversionWarning\n",
    "warnings.warn(\"Test DataConversionWarning\", DataConversionWarning)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>In the previous exercise sheets, you have implemented various algorithms from scratch; this exercise focuses on\n",
    "introducing you to a high-level Machine Learning library (sklearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Load the 20news-group-vectorized dataset from sklearn. This dataset consists of 130107 predictors\n",
    "with 20 classes. Perform the following experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the training dataset\n",
    "newsgroups_train = fetch_20newsgroups_vectorized(subset='train', return_X_y=True)\n",
    "newsgroups_test = fetch_20newsgroups_vectorized(subset='test', return_X_y=True)\n",
    "xtrain, ytrain = newsgroups_train\n",
    "xtest, ytest = newsgroups_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> a) Multiclass Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy %: 70.52575677110993\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.24      0.37       319\n",
      "           1       0.71      0.60      0.65       389\n",
      "           2       0.79      0.65      0.71       394\n",
      "           3       0.63      0.75      0.69       392\n",
      "           4       0.86      0.68      0.76       385\n",
      "           5       0.88      0.68      0.77       395\n",
      "           6       0.90      0.72      0.80       390\n",
      "           7       0.71      0.92      0.80       396\n",
      "           8       0.84      0.91      0.87       398\n",
      "           9       0.86      0.85      0.86       397\n",
      "          10       0.90      0.93      0.91       399\n",
      "          11       0.52      0.96      0.67       396\n",
      "          12       0.78      0.52      0.63       393\n",
      "          13       0.82      0.76      0.79       396\n",
      "          14       0.83      0.81      0.82       394\n",
      "          15       0.34      0.98      0.51       398\n",
      "          16       0.66      0.80      0.73       364\n",
      "          17       0.96      0.72      0.82       376\n",
      "          18       1.00      0.17      0.29       310\n",
      "          19       1.00      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.71      7532\n",
      "   macro avg       0.79      0.68      0.67      7532\n",
      "weighted avg       0.79      0.71      0.69      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain, ytrain)\n",
    "pred = clf.predict(xtest)\n",
    "print('Classification Accuracy %:', accuracy_score(ytest, pred)*100)\n",
    "print('Classification Report: ', classification_report(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> b) Use Logistic Regression Algorithm and perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>i. One vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy %: 72.65002655337229\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       319\n",
      "           1       0.63      0.68      0.65       389\n",
      "           2       0.72      0.66      0.69       394\n",
      "           3       0.68      0.62      0.65       392\n",
      "           4       0.71      0.70      0.71       385\n",
      "           5       0.72      0.69      0.70       395\n",
      "           6       0.72      0.86      0.79       390\n",
      "           7       0.80      0.78      0.79       396\n",
      "           8       0.79      0.88      0.83       398\n",
      "           9       0.69      0.82      0.75       397\n",
      "          10       0.86      0.86      0.86       399\n",
      "          11       0.86      0.81      0.84       396\n",
      "          12       0.63      0.62      0.62       393\n",
      "          13       0.65      0.63      0.64       396\n",
      "          14       0.85      0.85      0.85       394\n",
      "          15       0.70      0.89      0.78       398\n",
      "          16       0.62      0.80      0.69       364\n",
      "          17       0.85      0.79      0.82       376\n",
      "          18       0.68      0.46      0.55       310\n",
      "          19       0.72      0.27      0.40       251\n",
      "\n",
      "    accuracy                           0.73      7532\n",
      "   macro avg       0.73      0.71      0.71      7532\n",
      "weighted avg       0.73      0.73      0.72      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "clf.fit(xtrain, ytrain)\n",
    "pred = clf.predict(xtest)\n",
    "print('Classification Accuracy %:', accuracy_score(ytest, pred)*100)\n",
    "print('Classification Report: ', classification_report(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii. One vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy %: 0.6460435475305364\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52       319\n",
      "           1       0.52      0.64      0.57       389\n",
      "           2       0.70      0.57      0.63       394\n",
      "           3       0.62      0.56      0.59       392\n",
      "           4       0.67      0.61      0.64       385\n",
      "           5       0.67      0.64      0.65       395\n",
      "           6       0.66      0.85      0.74       390\n",
      "           7       0.69      0.69      0.69       396\n",
      "           8       0.69      0.78      0.73       398\n",
      "           9       0.58      0.68      0.63       397\n",
      "          10       0.85      0.77      0.81       399\n",
      "          11       0.86      0.70      0.77       396\n",
      "          12       0.52      0.54      0.53       393\n",
      "          13       0.48      0.55      0.51       396\n",
      "          14       0.84      0.75      0.79       394\n",
      "          15       0.62      0.78      0.69       398\n",
      "          16       0.54      0.73      0.62       364\n",
      "          17       0.80      0.72      0.76       376\n",
      "          18       0.57      0.40      0.47       310\n",
      "          19       0.66      0.21      0.32       251\n",
      "\n",
      "    accuracy                           0.65      7532\n",
      "   macro avg       0.65      0.63      0.63      7532\n",
      "weighted avg       0.66      0.65      0.64      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsOneClassifier(LogisticRegression())\n",
    "clf.fit(xtrain, ytrain)\n",
    "pred = clf.predict(xtest)\n",
    "print('Classification Accuracy %:', accuracy_score(ytest, pred))\n",
    "print('Classification Report: ', classification_report(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>c) Use Linear Discriminant Analysis Algorithm and perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>i. one vs. rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:blue\">LDA was running indefinitely till kernel crashes, which I beleive could have been a result of overload on RAM due to extremely high number of computations. Hence, I reduced the dataset dimensions, using TrauncatedSVD. TruncatedSVD is a dimensionality reduction method that can be used to reduce the number of features in a dataset while preserving as much information as possible. It is a variant of Singular Value Decomposition (SVD), which is a method for decomposing a matrix into its singular vectors and singular values. TruncatedSVD works by first computing the SVD of the input matrix, and then keeping only the top k singular vectors and corresponding singular values, where k is a user-specified parameter. This results in a reduced matrix with fewer columns (features) but which still contains most of the information from the original matrix.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TruncatedSVD instance with the desired number of dimensions (k)\n",
    "svd = TruncatedSVD(n_components=1000)\n",
    "# Use the fit_transform method to reduce the training set to k dimensions\n",
    "xtrain_reduced = svd.fit_transform(xtrain)\n",
    "xtest_reduced = svd.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the 20 newsgroups dataset\n",
    "# data = fetch_20newsgroups()\n",
    "\n",
    "# # Apply TruncatedSVD to the data\n",
    "# svd = TruncatedSVD(n_components=100)\n",
    "# X_reduced = svd.fit_transform(data.data)\n",
    "\n",
    "# Compute the explained variance ratio for each component\n",
    "evr = svd.explained_variance_ratio_\n",
    "\n",
    "# Plot the EVR as a function of the number of components\n",
    "plt.plot(evr)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy %: 0.7818640467339352\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.66       319\n",
      "           1       0.64      0.74      0.68       389\n",
      "           2       0.71      0.70      0.70       394\n",
      "           3       0.60      0.71      0.65       392\n",
      "           4       0.78      0.76      0.77       385\n",
      "           5       0.84      0.69      0.75       395\n",
      "           6       0.83      0.84      0.83       390\n",
      "           7       0.87      0.84      0.86       396\n",
      "           8       0.97      0.89      0.93       398\n",
      "           9       0.92      0.88      0.90       397\n",
      "          10       0.94      0.91      0.93       399\n",
      "          11       0.97      0.85      0.90       396\n",
      "          12       0.60      0.77      0.68       393\n",
      "          13       0.85      0.80      0.82       396\n",
      "          14       0.93      0.86      0.89       394\n",
      "          15       0.73      0.90      0.80       398\n",
      "          16       0.71      0.86      0.78       364\n",
      "          17       0.97      0.73      0.83       376\n",
      "          18       0.65      0.59      0.62       310\n",
      "          19       0.53      0.52      0.52       251\n",
      "\n",
      "    accuracy                           0.78      7532\n",
      "   macro avg       0.79      0.77      0.78      7532\n",
      "weighted avg       0.79      0.78      0.78      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a LinearDiscriminantAnalysis object\n",
    "lda = OneVsRestClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto', tol='1.0e-2'))\n",
    "# Fit the model to the data\n",
    "lda.fit(xtrain_reduced, ytrain)\n",
    "# Use the trained model to predict the class of new data\n",
    "pred = lda.predict(xtest_reduced)\n",
    "print('Classification Accuracy %:', accuracy_score(ytest, pred))\n",
    "print('Classification Report: ', classification_report(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii. One vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy %: 0.7668613913967074\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69       319\n",
      "           1       0.63      0.69      0.66       389\n",
      "           2       0.72      0.68      0.70       394\n",
      "           3       0.62      0.66      0.64       392\n",
      "           4       0.75      0.75      0.75       385\n",
      "           5       0.77      0.70      0.73       395\n",
      "           6       0.82      0.86      0.84       390\n",
      "           7       0.83      0.83      0.83       396\n",
      "           8       0.94      0.89      0.91       398\n",
      "           9       0.90      0.85      0.87       397\n",
      "          10       0.93      0.90      0.92       399\n",
      "          11       0.90      0.84      0.87       396\n",
      "          12       0.65      0.71      0.67       393\n",
      "          13       0.74      0.72      0.73       396\n",
      "          14       0.85      0.82      0.84       394\n",
      "          15       0.76      0.88      0.82       398\n",
      "          16       0.70      0.84      0.76       364\n",
      "          17       0.90      0.79      0.84       376\n",
      "          18       0.63      0.56      0.59       310\n",
      "          19       0.55      0.51      0.52       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.76      0.76      0.76      7532\n",
      "weighted avg       0.77      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsOneClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto', tol='1.0e-2'))\n",
    "clf.fit(xtrain_reduced, ytrain)\n",
    "pred = clf.predict(xtest_reduced)\n",
    "print('Classification Accuracy %:', accuracy_score(ytest, pred))\n",
    "print('Classification Report: ', classification_report(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Variable Selection via Forward and Backward Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load the dataset regression.npy, the dataset consists of over 100 predictors. We generated the regression\n",
    "dataset such that only a few predictors are relevant. Perform the following experiments using the least angle\n",
    "regression algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Forward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regression.npy', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "    y = np.load(f)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "n, m = X.shape\n",
    "split = int(0.8 * n)\n",
    "p = np.random.permutation(n)\n",
    "ones = np.ones(shape=X.shape[0]).reshape(-1, 1)\n",
    "x_data = preprocessing.normalize(X) # NORMALIZING HERE!!!!!!!!!!!\n",
    "x_data = np.concatenate((ones,x_data), 1)\n",
    "x_train1 = x_data[p[:split]]\n",
    "y_train1 = y[p[:split]]\n",
    "x_valid1 = x_data[p[split:]]\n",
    "y_valid1 = y[p[split:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Forward search with SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features obtained: [0, 1, 2, 3, 4, 6, 7, 12, 14, 17, 21, 22, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 46, 47, 49, 50, 51, 54, 55, 60, 61, 62, 65, 69, 72, 74, 76, 78, 79, 80, 81, 84, 86, 90, 96, 97]\n",
      "MSE from Forward Search:\n",
      " 8.644464865020298\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.Lars().fit(x_train1, y_train1)\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select= 50, direction=\"forward\").fit(X, y)\n",
    "features_boolean = sfs.get_support().tolist()\n",
    "\n",
    "feature_list = []\n",
    "for i in range(len(features_boolean)):\n",
    "    if features_boolean[i]:\n",
    "        feature_list.append(i)\n",
    "\n",
    "print(\"Features obtained:\", feature_list)\n",
    "lars_new_model = Lars()\n",
    "lars_new_model.fit(x_train1[:,feature_list],y_train1)\n",
    "predictions = lars_new_model.predict(x_valid1[:,feature_list])\n",
    "mseScore = mean_squared_error(y_valid1,predictions)\n",
    "print(\"MSE from Forward Search:\\n\",mseScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(x_train, y_train, x_valid, y_valid):\n",
    "    model = linear_model.Lars().fit(x_train, y_train)\n",
    "    coef = model.coef_\n",
    "    predictions= model.predict(x_valid)\n",
    "    error_computed = mean_squared_error(y_valid, predictions)\n",
    "    return error_computed, coef, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Custom Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_search(x_train, y_train, x_valid, y_valid):\n",
    "    M = x_train.shape[1]; totalFeatures = set(range(M)); features = set(); initial_error = np.inf; best_feature = not None\n",
    "    while best_feature is not None:\n",
    "        best_feature = None; best_error = initial_error\n",
    "        for f in totalFeatures - features:\n",
    "            add_new_feature = list(features | {f})\n",
    "            error_computed, coef, _ = performance(x_train[:, add_new_feature], y_train, x_valid[:, add_new_feature], y_valid)\n",
    "            if error_computed < best_error:\n",
    "                best_feature = f\n",
    "                best_error = error_computed\n",
    "        if best_error < initial_error:\n",
    "            features = features | {best_feature}\n",
    "            initial_error = best_error\n",
    "    return features, best_error, coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward search features: \n",
      " {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 31, 32, 34, 36, 39, 41, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 58, 61, 62, 63, 64, 65, 66, 69, 74, 75, 76, 77, 78, 80, 81, 82, 84, 86, 88, 89, 90, 93, 97, 100}\n",
      "forward best MSE: \n",
      " 6.261936532911846\n"
     ]
    }
   ],
   "source": [
    "featuresForward, mseForward, fwdCoef = forward_search(x_train1 , y_train1 , x_valid1 , y_valid1)\n",
    "print('forward search features: \\n', featuresForward)\n",
    "print('forward best MSE: \\n', mseForward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Backward Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Backward Search with SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features obtained: [0, 1, 2, 3, 4, 6, 7, 12, 14, 17, 21, 22, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 46, 47, 49, 50, 51, 54, 55, 60, 61, 62, 65, 69, 72, 74, 76, 78, 79, 80, 81, 84, 86, 90, 96, 97]\n",
      "MSE from Backward Search:\n",
      "  8.644464865020298\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.Lars().fit(x_train1, y_train1)\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select= 50, direction=\"backward\").fit(X, y)\n",
    "features_boolean = sfs.get_support().tolist()\n",
    "\n",
    "feature_list = []\n",
    "for i in range(len(features_boolean)):\n",
    "    if features_boolean[i]:\n",
    "        feature_list.append(i)\n",
    "\n",
    "print(\"Features obtained:\", feature_list)\n",
    "lars_new_model = Lars()\n",
    "lars_new_model.fit(x_train1[:,feature_list],y_train1)\n",
    "predictions = lars_new_model.predict(x_valid1[:,feature_list])\n",
    "mseScore = mean_squared_error(y_valid1,predictions)\n",
    "print(\"MSE from Backward Search:\\n \",mseScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Custom Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_search(x_train, y_train, x_valid, y_valid):\n",
    "    M = x_train.shape[1]\n",
    "    features = set(range(M))\n",
    "    best_feature = 1\n",
    "    error = np.inf\n",
    "    while best_feature is not None:\n",
    "        best_feature = None\n",
    "        best_error = error\n",
    "        for f in features:\n",
    "            add_new_feature = list(features-{f})\n",
    "            error_computed, coef, _ = performance(x_train[:, :len(add_new_feature)], y_train, x_valid[:, :len(add_new_feature)], y_valid)\n",
    "            if error_computed < best_error:\n",
    "                best_feature = f\n",
    "                best_error = error_computed\n",
    "        if best_error < error:\n",
    "            features = features - {best_feature}\n",
    "            error = best_error\n",
    "    return features, best_error, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward search features: \n",
      " {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100}\n",
      "backward best MSE: \n",
      " 6.340086059859352\n"
     ]
    }
   ],
   "source": [
    "featuresBackward, mseBackward, bckCoef = backward_search(x_train1 , y_train1 , x_valid1 , y_valid1 )\n",
    "print('backward search features: \\n', featuresBackward)\n",
    "print('backward best MSE: \\n', mseBackward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Print out the indices of the selected features, compare the outputs of the two methods. Are the indices the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:blue\">The features from ForwardSearch and BackwardSearch are not the same</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward search features: \n",
      " {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 31, 32, 34, 36, 39, 41, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 58, 61, 62, 63, 64, 65, 66, 69, 74, 75, 76, 77, 78, 80, 81, 82, 84, 86, 88, 89, 90, 93, 97, 100}\n",
      "backward search features: \n",
      " {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100}\n"
     ]
    }
   ],
   "source": [
    "print('forward search features: \\n', featuresForward)\n",
    "print('backward search features: \\n', featuresBackward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Variable selection via forward and backward search drops some predictors; in some cases, we don’t want to remove\n",
    "these predictors. Rather we want their coefficients to be small as possible. We are going to test the effect of the\n",
    "regularization term alpha. Try the following alpha values: [10, 1, 0.1, 0.0001, 0.00001 ], use regression.npy\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseList = []\n",
    "alphaList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>a) Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001}\n",
      "Mean squared error is:  6.285025173533575\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "param_grid = {'alpha': [10, 1, 0.1, 0.0001, 0.00001 ]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "print(grid_search.best_params_)\n",
    "optimumAlpha = grid_search.best_params_['alpha']\n",
    "\n",
    "model = Ridge(alpha = optimumAlpha)\n",
    "model.fit(x_train1, y_train1)\n",
    "gRidgeCoef = model.coef_\n",
    "# print('coeffs are: ', model.coef_)\n",
    "\n",
    "pred = model.predict(x_valid1)\n",
    "score = mean_squared_error(y_valid1, pred)\n",
    "print('Mean squared error is: ', score)\n",
    "# score = model.score(x_valid1, y_valid1)\n",
    "# print('R2 error is: ', score)\n",
    "mseList.append(score)\n",
    "alphaList.append(optimumAlpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>b) Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05}\n",
      "Mean squared error is:  6.285763008577142\n"
     ]
    }
   ],
   "source": [
    "model = Lasso()\n",
    "param_grid = {'alpha': [10, 1, 0.1, 0.0001, 0.00001 ]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "print(grid_search.best_params_)\n",
    "optimumAlpha = grid_search.best_params_['alpha']\n",
    "\n",
    "model = Lasso(alpha = optimumAlpha)\n",
    "model.fit(x_train1, y_train1)\n",
    "gLassoCoef = model.coef_\n",
    "# print('coeffs are: ', model.coef_)\n",
    "\n",
    "pred = model.predict(x_valid1)\n",
    "score = mean_squared_error(y_valid1, pred)\n",
    "print('Mean squared error is: ', score)\n",
    "# score = model.score(x_valid1, y_valid1)\n",
    "# print('R2 error is: ', score)\n",
    "mseList.append(score)\n",
    "alphaList.append(optimumAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>c) Elastic-Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05}\n",
      "Mean squared error is:  6.285619301264818\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "param_grid = {'alpha': [10, 1, 0.1, 0.0001, 0.00001 ]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train1, y_train1)\n",
    "print(grid_search.best_params_)\n",
    "optimumAlpha = grid_search.best_params_['alpha']\n",
    "\n",
    "model = ElasticNet(alpha = optimumAlpha)\n",
    "model.fit(x_train1, y_train1)\n",
    "gElasticCoef = model.coef_\n",
    "pred = model.predict(x_valid1)\n",
    "score = mean_squared_error(y_valid1, pred)\n",
    "print('Mean squared error is: ', score)\n",
    "# score = model.score(x_valid1, y_valid1)\n",
    "# print('R2 error is: ', score)\n",
    "mseList.append(score)\n",
    "alphaList.append(optimumAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. RandomSearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>a) Ridge regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001}\n",
      "Mean squared error is:  6.285025173533575\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "random_search = RandomizedSearchCV(model, param_grid, cv=5)\n",
    "random_search.fit(x_train1, y_train1)\n",
    "print(random_search.best_params_)\n",
    "optimumAlpha = random_search.best_params_['alpha']\n",
    "\n",
    "model = Ridge(alpha = optimumAlpha)\n",
    "model.fit(x_train1, y_train1)\n",
    "pred = model.predict(x_valid1)\n",
    "score = mean_squared_error(y_valid1, pred)\n",
    "print('Mean squared error is: ', score)\n",
    "# score = model.score(x_valid1, y_valid1)\n",
    "# print('R2 error is: ', score)\n",
    "mseList.append(score)\n",
    "alphaList.append(optimumAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>b) Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05}\n",
      "Mean squared error is:  6.285763008577142\n"
     ]
    }
   ],
   "source": [
    "model = Lasso()\n",
    "random_search = RandomizedSearchCV(model, param_grid, cv=5)\n",
    "random_search.fit(x_train1, y_train1)\n",
    "print(random_search.best_params_)\n",
    "optimumAlpha = random_search.best_params_['alpha']\n",
    "\n",
    "model = Lasso(alpha = optimumAlpha)\n",
    "model.fit(x_train1, y_train1)\n",
    "pred = model.predict(x_valid1)\n",
    "score = mean_squared_error(y_valid1, pred)\n",
    "print('Mean squared error is: ', score)\n",
    "# score = model.score(x_valid1, y_valid1)\n",
    "# print('R2 error is: ', score)\n",
    "mseList.append(score)\n",
    "alphaList.append(optimumAlpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>c) Elastic-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05}\n",
      "Mean squared error is:  6.285619301264818\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "random_search = RandomizedSearchCV(model, param_grid, cv=5)\n",
    "random_search.fit(x_train1, y_train1)\n",
    "print(random_search.best_params_)\n",
    "optimumAlpha = random_search.best_params_['alpha']\n",
    "\n",
    "model = ElasticNet(alpha = optimumAlpha)\n",
    "model.fit(x_train1, y_train1)\n",
    "pred = model.predict(x_valid1)\n",
    "# print('coeffs are: ', )\n",
    "score = mean_squared_error(y_valid1, pred)\n",
    "print('Mean squared error is: ', score)\n",
    "# score = model.score(x_valid1, y_valid1)\n",
    "# print('R2 error is: ', score)\n",
    "mseList.append(score)\n",
    "alphaList.append(optimumAlpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.285025173533575, 0.0001)\n",
      "(6.285763008577142, 1e-05)\n",
      "(6.285619301264818, 1e-05)\n",
      "(6.285025173533575, 0.0001)\n",
      "(6.285763008577142, 1e-05)\n",
      "(6.285619301264818, 1e-05)\n"
     ]
    }
   ],
   "source": [
    "for i in list(zip(mseList, alphaList)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Briefly discuss the effect of high and low values of alpha. Then, return the best three models with their respective alpha values using the appropriate metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span style=\"color:blue\">High values of alpha will result in more regularization, which can help prevent overfitting and improve the stability and interpretability of the model. However, if the value of alpha is too high, it can also cause underfitting by reducing the model's flexibility and ability to fit the data. On the other hand, low values of alpha will result in less regularization, allowing the model to have more flexibility and potentially fit the data better. However, if the value of alpha is too low, the model may overfit the data and produce unstable or unreliable results.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Compare the best three models to the models from question 2. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span style=\"color:blue\">Since the results are the same for Gridsearchcv and Randomsearch, which makes sense as these algorithms find the optimum value for alpha, which lead to the minimization of the cost. I will pick the first three alpha parameters.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a) Ridge regression\n",
    "b) Lasso\n",
    "c) Elastic-Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseBar = mseList[:3]\n",
    "mseBar.append(mseForward)\n",
    "mseBar.append(mseBackward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge, Lasso, ElasticNet, ForwardSearch, FackwardSearch\n",
      " [6.285025173533575, 6.285763008577142, 6.285619301264818, 6.261936532911846, 6.340086059859352]\n"
     ]
    }
   ],
   "source": [
    "print('Ridge, Lasso, ElasticNet, ForwardSearch, FackwardSearch\\n', mseBar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE is from Forward Search:  6.261936532911846\n"
     ]
    }
   ],
   "source": [
    "mseBar.index(min(mseBar))\n",
    "print('Minimum MSE is from Forward Search: ', mseBar[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span style=\"color:blue\">As per the results, the best performing model in this case if Forward Search which gives the best results, which could be due to the fact that the weights might have diminished but not gone to 0 entirely which might be reflected as this slight increase in the error as compared to Forward Search which completely removes the columns that do not positively affect the minimization of the error. However, this is not a global case, and usually this leads to poor solutions and curating a list of features which are not the best, however in this case it performed good.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Get the indices of the top k coefficient of these three models and compare them with the features selected\n",
    "via the forward and back search method. Feel free to try different values of k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span style=\"color:blue\">From the outputs below, we can observer for all the models all the dominant features are the same at the positions 0 1 2 3 4 5</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span style=\"color:blue\"></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_k(arr, k):\n",
    "    # Compute the indices of the k largest values in the array\n",
    "    indices = np.argpartition(arr, -k)[-k:]\n",
    "    # Extract the maximum k values and their positions from the array\n",
    "    max_k_values = arr[indices]\n",
    "    max_k_positions = np.argsort(arr[indices])[::-1]\n",
    "    # Sort the array of maximum k values according to the positions of the maximum k values in the original array\n",
    "    sorted_max_k_values = max_k_values[np.argsort(max_k_positions)]\n",
    "    return sorted_max_k_values, max_k_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gRidgeCoef[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gLassoCoef[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gElasticCoef[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwdCoef[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bckCoef[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient values: [61.1434036  41.48622485 40.75673856 32.34406106  4.44094882] \n",
      " positions: [4 3 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "vals, coefs = max_k(gRidgeCoef, k)\n",
    "print('coefficient values: {} \\n positions: {}'.format(vals, coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient values: [61.10246672 41.44295062 40.71421231 32.30407641  4.39925742] \n",
      " positions: [4 3 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "vals, coefs = max_k(gLassoCoef, k)\n",
    "print('coefficient values: {} \\n positions: {}'.format(vals, coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient values: [40.57667876 41.29854761  4.33418192 32.1861859  60.92444053] \n",
      " positions: [2 3 4 1 0]\n"
     ]
    }
   ],
   "source": [
    "vals, coefs = max_k(gElasticCoef, k)\n",
    "print('coefficient values: {} \\n positions: {}'.format(vals, coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient values: [39.5918596  38.89117224  2.14385536 59.31896068 30.50583422] \n",
      " positions: [2 4 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "vals, coefs = max_k(fwdCoef, k)\n",
    "print('coefficient values: {} \\n positions: {}'.format(vals, coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient values: [41.92919566 41.156475    4.94033556 61.67931821 32.89247886] \n",
      " positions: [2 4 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "vals, coefs = max_k(bckCoef, k)\n",
    "print('coefficient values: {} \\n positions: {}'.format(vals, coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sklearn is a very powerful high-level Machine learning API. It has a clean implementation of almost all the\n",
    "popular machine-learning algorithms. This task will introduce you to how to write a custom estimator in sklearn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a python class called MyLinearRegression\n",
    "2. Ensure your class inherit from sklearn BaseEstimator and RegressorMixin\n",
    "3. Implement fit(X,Y) method, and returns self\n",
    "4. Implement predict(X) method\n",
    "5. Use check estimator() method to know if your estimator(MyLinearRegression) is valid\n",
    "6. Fit the dataset below using your custom estimator. Remember 80:20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas [-1.34714286] 5.435\n",
      "R2 score is:  -2584.778304773561\n",
      "mean squares error is:  46.946241666666644\n"
     ]
    }
   ],
   "source": [
    "class MyLinearRegression(BaseEstimator, RegressorMixin):\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        reg = LinearRegression()\n",
    "        \n",
    "        reg.fit(X, y)\n",
    "        # self.set_params = reg.get_params\n",
    "        self.coef_ = reg.coef_\n",
    "        self.intercept_ = reg.intercept_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        try:\n",
    "            y_pred = X @ self.coef_\n",
    "        except:\n",
    "            print('x shape is:', X.shape)\n",
    "            cof = np.asanyarray(self.coef_)\n",
    "            print('cof shape: ', cof.shape)\n",
    "            y_pred = np.zeros(X.shape[1])\n",
    "        y_pred = y_pred.astype(float64)\n",
    "        if any(isnan(y_pred)) or any(isinf(y_pred)):\n",
    "            raise ValueError('predict() produced NaN or inf values!')\n",
    "\n",
    "        return np.ravel(y_pred)\n",
    "\n",
    "\n",
    "reg = MyLinearRegression()\n",
    "\n",
    "#training data\n",
    "x_train = np.array([0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]).reshape(-1, 1)\n",
    "y_train = np.array([6.0, 4.83, 3.7, 3.15, 2.41, 1.83, 1.49, 1.21]).reshape(-1, 1)\n",
    "\n",
    "#test data\n",
    "X_test = np.array([4.5, 5.0, 4.0]).reshape(-1, 1)\n",
    "y_test = np.array([0.73, 0.64,  0.96]).reshape(-1, 1)\n",
    "\n",
    "sel = reg.fit(x_train, y_train)\n",
    "print('betas',sel.coef_,sel.intercept_)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "score = reg.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('R2 score is: ', score)\n",
    "print('mean squares error is: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "estimator = MyLinearRegression()\n",
    "gen = check_estimator(estimator, generate_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some tests failed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "estimator = MyLinearRegression()\n",
    "# check_estimator(estimator)\n",
    "try:\n",
    "    check_estimator(estimator)\n",
    "except:\n",
    "    print('Some tests failed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
